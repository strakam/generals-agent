digraph {
	graph [size="106.35,106.35"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	126407094920736 [label="
 (1, 256, 24, 24)" fillcolor=darkolivegreen1]
	126407098360176 [label=AddBackward0]
	126407094694624 -> 126407098360176
	126407094694624 [label=ReluBackward0]
	126407094692944 -> 126407094694624
	126407094692944 [label=ConvolutionBackward0]
	126407094693664 -> 126407094692944
	126407094693664 [label=AddBackward0]
	126407094693376 -> 126407094693664
	126407094693376 [label=ReluBackward0]
	126407094694192 -> 126407094693376
	126407094694192 [label=ConvolutionBackward0]
	126407094693952 -> 126407094694192
	126407094693952 [label=AddBackward0]
	126407094694288 -> 126407094693952
	126407094694288 [label=ReluBackward0]
	126407094693232 -> 126407094694288
	126407094693232 [label=ConvolutionBackward0]
	126407094693568 -> 126407094693232
	126407094693568 [label=AddBackward0]
	126407094693040 -> 126407094693568
	126407094693040 [label=ReluBackward0]
	126407094693712 -> 126407094693040
	126407094693712 [label=ConvolutionBackward0]
	126407094694912 -> 126407094693712
	126407094694912 [label=AddBackward0]
	126407094695104 -> 126407094694912
	126407094695104 [label=ReluBackward0]
	126407094695248 -> 126407094695104
	126407094695248 [label=ConvolutionBackward0]
	126407094695344 -> 126407094695248
	126407094695344 [label=AddBackward0]
	126407094695536 -> 126407094695344
	126407094695536 [label=ReluBackward0]
	126407094695680 -> 126407094695536
	126407094695680 [label=ConvolutionBackward0]
	126407094695776 -> 126407094695680
	126407094695776 [label=AddBackward0]
	126407094695968 -> 126407094695776
	126407094695968 [label=ReluBackward0]
	126407094696112 -> 126407094695968
	126407094696112 [label=ConvolutionBackward0]
	126407094696208 -> 126407094696112
	126407094696208 [label=AddBackward0]
	126407094696400 -> 126407094696208
	126407094696400 [label=ReluBackward0]
	126407094696544 -> 126407094696400
	126407094696544 [label=ConvolutionBackward0]
	126407094696640 -> 126407094696544
	126407094696640 [label=AddBackward0]
	126407094696832 -> 126407094696640
	126407094696832 [label=ReluBackward0]
	126407094696976 -> 126407094696832
	126407094696976 [label=ConvolutionBackward0]
	126407094697072 -> 126407094696976
	126407094697072 [label=AddBackward0]
	126407094697264 -> 126407094697072
	126407094697264 [label=ReluBackward0]
	126407094697408 -> 126407094697264
	126407094697408 [label=ConvolutionBackward0]
	126407094697504 -> 126407094697408
	126407094697504 [label=AddBackward0]
	126407094697696 -> 126407094697504
	126407094697696 [label=ReluBackward0]
	126407094697840 -> 126407094697696
	126407094697840 [label=ConvolutionBackward0]
	126407094697936 -> 126407094697840
	126407094697936 [label=AddBackward0]
	126407054606544 -> 126407094697936
	126407054606544 [label=ReluBackward0]
	126407054606688 -> 126407054606544
	126407054606688 [label=ConvolutionBackward0]
	126407054606784 -> 126407054606688
	126407054606784 [label=AddBackward0]
	126407054606976 -> 126407054606784
	126407054606976 [label=ReluBackward0]
	126407054607120 -> 126407054606976
	126407054607120 [label=ConvolutionBackward0]
	126407054607216 -> 126407054607120
	126407054607216 [label=AddBackward0]
	126407054607408 -> 126407054607216
	126407054607408 [label=ReluBackward0]
	126407054607552 -> 126407054607408
	126407054607552 [label=ConvolutionBackward0]
	126407054607648 -> 126407054607552
	126407054607648 [label=AddBackward0]
	126407054607840 -> 126407054607648
	126407054607840 [label=ReluBackward0]
	126407054607984 -> 126407054607840
	126407054607984 [label=ConvolutionBackward0]
	126407054608080 -> 126407054607984
	126407054608080 [label=AddBackward0]
	126407054608272 -> 126407054608080
	126407054608272 [label=ReluBackward0]
	126407054608416 -> 126407054608272
	126407054608416 [label=ConvolutionBackward0]
	126407054608512 -> 126407054608416
	126407054608512 [label=AddBackward0]
	126407054608704 -> 126407054608512
	126407054608704 [label=ReluBackward0]
	126407054608848 -> 126407054608704
	126407054608848 [label=ConvolutionBackward0]
	126407054608944 -> 126407054608848
	126407054608944 [label=ReluBackward0]
	126407054609136 -> 126407054608944
	126407054609136 [label=ConvolutionBackward0]
	126407054609232 -> 126407054609136
	126407054609232 [label=AddBackward0]
	126407054609424 -> 126407054609232
	126407054609424 [label=ReluBackward0]
	126407054609568 -> 126407054609424
	126407054609568 [label=ConvolutionBackward0]
	126407054609664 -> 126407054609568
	126407054609664 [label=ReluBackward0]
	126407054609856 -> 126407054609664
	126407054609856 [label=ConvolutionBackward0]
	126407054609952 -> 126407054609856
	126407054609952 [label=AddBackward0]
	126407054610144 -> 126407054609952
	126407054610144 [label=ReluBackward0]
	126407054610288 -> 126407054610144
	126407054610288 [label=ConvolutionBackward0]
	126407054610384 -> 126407054610288
	126407054610384 [label=ReluBackward0]
	126407054610576 -> 126407054610384
	126407054610576 [label=ConvolutionBackward0]
	126407054610672 -> 126407054610576
	126407054610672 [label=AddBackward0]
	126407054610864 -> 126407054610672
	126407054610864 [label=ReluBackward0]
	126407054611008 -> 126407054610864
	126407054611008 [label=ConvolutionBackward0]
	126407054611104 -> 126407054611008
	126407054611104 [label=ReluBackward0]
	126407054611296 -> 126407054611104
	126407054611296 [label=ConvolutionBackward0]
	126407054611344 -> 126407054611296
	126407054611344 [label=AddBackward0]
	126407054611632 -> 126407054611344
	126407054611632 [label=ReluBackward0]
	126407054611776 -> 126407054611632
	126407054611776 [label=ConvolutionBackward0]
	126407054611824 -> 126407054611776
	126407054611824 [label=ReluBackward0]
	126407054612112 -> 126407054611824
	126407054612112 [label=ConvolutionBackward0]
	126407054612160 -> 126407054612112
	126407054612160 [label=AddBackward0]
	126407054612448 -> 126407054612160
	126407054612448 [label=ReluBackward0]
	126407054612592 -> 126407054612448
	126407054612592 [label=ConvolutionBackward0]
	126407054612640 -> 126407054612592
	126407054612640 [label=ReluBackward0]
	126407054612928 -> 126407054612640
	126407054612928 [label=ConvolutionBackward0]
	126407054612976 -> 126407054612928
	126407054612976 [label=AddBackward0]
	126407054613264 -> 126407054612976
	126407054613264 [label=ReluBackward0]
	126407054613408 -> 126407054613264
	126407054613408 [label=ConvolutionBackward0]
	126407054613456 -> 126407054613408
	126407054613456 [label=ReluBackward0]
	126407054613744 -> 126407054613456
	126407054613744 [label=ConvolutionBackward0]
	126407054613792 -> 126407054613744
	126407054613792 [label=AddBackward0]
	126407054614080 -> 126407054613792
	126407054614080 [label=ReluBackward0]
	126407054614224 -> 126407054614080
	126407054614224 [label=ConvolutionBackward0]
	126407054614272 -> 126407054614224
	126407054614272 [label=ReluBackward0]
	126407054614560 -> 126407054614272
	126407054614560 [label=ConvolutionBackward0]
	126407054614608 -> 126407054614560
	126407054614608 [label=ReluBackward0]
	126407054614896 -> 126407054614608
	126407054614896 [label=ConvolutionBackward0]
	126407054614944 -> 126407054614896
	126407094725488 [label="first_conv.0.weight
 (256, 55, 3, 3)" fillcolor=lightblue]
	126407094725488 -> 126407054614944
	126407054614944 [label=AccumulateGrad]
	126407054614800 -> 126407054614896
	126407094725568 [label="first_conv.0.bias
 (256)" fillcolor=lightblue]
	126407094725568 -> 126407054614800
	126407054614800 [label=AccumulateGrad]
	126407054614464 -> 126407054614560
	126407094725728 [label="encoder_stages.0.0.conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	126407094725728 -> 126407054614464
	126407054614464 [label=AccumulateGrad]
	126407054614704 -> 126407054614560
	126407094725808 [label="encoder_stages.0.0.conv.0.bias
 (128)" fillcolor=lightblue]
	126407094725808 -> 126407054614704
	126407054614704 [label=AccumulateGrad]
	126407054614128 -> 126407054614224
	126407094725968 [label="encoder_stages.0.0.conv.2.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	126407094725968 -> 126407054614128
	126407054614128 [label=AccumulateGrad]
	126407054614368 -> 126407054614224
	126407094726048 [label="encoder_stages.0.0.conv.2.bias
 (256)" fillcolor=lightblue]
	126407094726048 -> 126407054614368
	126407054614368 [label=AccumulateGrad]
	126407054614032 -> 126407054613792
	126407054614032 [label=ConvolutionBackward0]
	126407054614608 -> 126407054614032
	126407054614752 -> 126407054614032
	126407094726208 [label="encoder_stages.0.0.residual_conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	126407094726208 -> 126407054614752
	126407054614752 [label=AccumulateGrad]
	126407054614416 -> 126407054614032
	126407094726288 [label="encoder_stages.0.0.residual_conv.bias
 (256)" fillcolor=lightblue]
	126407094726288 -> 126407054614416
	126407054614416 [label=AccumulateGrad]
	126407054613648 -> 126407054613744
	126407094726448 [label="encoder_stages.0.1.conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	126407094726448 -> 126407054613648
	126407054613648 [label=AccumulateGrad]
	126407054613888 -> 126407054613744
	126407094726528 [label="encoder_stages.0.1.conv.0.bias
 (128)" fillcolor=lightblue]
	126407094726528 -> 126407054613888
	126407054613888 [label=AccumulateGrad]
	126407054613312 -> 126407054613408
	126407094726688 [label="encoder_stages.0.1.conv.2.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	126407094726688 -> 126407054613312
	126407054613312 [label=AccumulateGrad]
	126407054613552 -> 126407054613408
	126407094726768 [label="encoder_stages.0.1.conv.2.bias
 (256)" fillcolor=lightblue]
	126407094726768 -> 126407054613552
	126407054613552 [label=AccumulateGrad]
	126407054613216 -> 126407054612976
	126407054613216 [label=ConvolutionBackward0]
	126407054613792 -> 126407054613216
	126407054613936 -> 126407054613216
	126407094726928 [label="encoder_stages.0.1.residual_conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	126407094726928 -> 126407054613936
	126407054613936 [label=AccumulateGrad]
	126407054613600 -> 126407054613216
	126407094727008 [label="encoder_stages.0.1.residual_conv.bias
 (256)" fillcolor=lightblue]
	126407094727008 -> 126407054613600
	126407054613600 [label=AccumulateGrad]
	126407054612832 -> 126407054612928
	126407094727168 [label="encoder_stages.0.2.conv.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	126407094727168 -> 126407054612832
	126407054612832 [label=AccumulateGrad]
	126407054613072 -> 126407054612928
	126407094727248 [label="encoder_stages.0.2.conv.0.bias
 (128)" fillcolor=lightblue]
	126407094727248 -> 126407054613072
	126407054613072 [label=AccumulateGrad]
	126407054612496 -> 126407054612592
	126407094727408 [label="encoder_stages.0.2.conv.2.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	126407094727408 -> 126407054612496
	126407054612496 [label=AccumulateGrad]
	126407054612736 -> 126407054612592
	126407094727488 [label="encoder_stages.0.2.conv.2.bias
 (256)" fillcolor=lightblue]
	126407094727488 -> 126407054612736
	126407054612736 [label=AccumulateGrad]
	126407054612400 -> 126407054612160
	126407054612400 [label=ConvolutionBackward0]
	126407054612976 -> 126407054612400
	126407054613120 -> 126407054612400
	126407094727648 [label="encoder_stages.0.2.residual_conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	126407094727648 -> 126407054613120
	126407054613120 [label=AccumulateGrad]
	126407054612784 -> 126407054612400
	126407094727728 [label="encoder_stages.0.2.residual_conv.bias
 (256)" fillcolor=lightblue]
	126407094727728 -> 126407054612784
	126407054612784 [label=AccumulateGrad]
	126407054612016 -> 126407054612112
	126407094727888 [label="encoder_stages.1.0.conv.0.weight
 (160, 256, 3, 3)" fillcolor=lightblue]
	126407094727888 -> 126407054612016
	126407054612016 [label=AccumulateGrad]
	126407054612256 -> 126407054612112
	126407094727968 [label="encoder_stages.1.0.conv.0.bias
 (160)" fillcolor=lightblue]
	126407094727968 -> 126407054612256
	126407054612256 [label=AccumulateGrad]
	126407054611680 -> 126407054611776
	126407094728128 [label="encoder_stages.1.0.conv.2.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094728128 -> 126407054611680
	126407054611680 [label=AccumulateGrad]
	126407054611920 -> 126407054611776
	126407094728208 [label="encoder_stages.1.0.conv.2.bias
 (320)" fillcolor=lightblue]
	126407094728208 -> 126407054611920
	126407054611920 [label=AccumulateGrad]
	126407054611584 -> 126407054611344
	126407054611584 [label=ConvolutionBackward0]
	126407054612160 -> 126407054611584
	126407054612304 -> 126407054611584
	126407094728368 [label="encoder_stages.1.0.residual_conv.weight
 (320, 256, 1, 1)" fillcolor=lightblue]
	126407094728368 -> 126407054612304
	126407054612304 [label=AccumulateGrad]
	126407054611968 -> 126407054611584
	126407094728448 [label="encoder_stages.1.0.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094728448 -> 126407054611968
	126407054611968 [label=AccumulateGrad]
	126407054611200 -> 126407054611296
	126407094728608 [label="encoder_stages.1.1.conv.0.weight
 (160, 320, 3, 3)" fillcolor=lightblue]
	126407094728608 -> 126407054611200
	126407054611200 [label=AccumulateGrad]
	126407054611440 -> 126407054611296
	126407094728688 [label="encoder_stages.1.1.conv.0.bias
 (160)" fillcolor=lightblue]
	126407094728688 -> 126407054611440
	126407054611440 [label=AccumulateGrad]
	126407054611056 -> 126407054611008
	126407094728848 [label="encoder_stages.1.1.conv.2.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094728848 -> 126407054611056
	126407054611056 [label=AccumulateGrad]
	126407054610912 -> 126407054611008
	126407094728928 [label="encoder_stages.1.1.conv.2.bias
 (320)" fillcolor=lightblue]
	126407094728928 -> 126407054610912
	126407054610912 [label=AccumulateGrad]
	126407054610816 -> 126407054610672
	126407054610816 [label=ConvolutionBackward0]
	126407054611344 -> 126407054610816
	126407054611488 -> 126407054610816
	126407094729088 [label="encoder_stages.1.1.residual_conv.weight
 (320, 320, 1, 1)" fillcolor=lightblue]
	126407094729088 -> 126407054611488
	126407054611488 [label=AccumulateGrad]
	126407054611152 -> 126407054610816
	126407094729168 [label="encoder_stages.1.1.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094729168 -> 126407054611152
	126407054611152 [label=AccumulateGrad]
	126407054610624 -> 126407054610576
	126407094729328 [label="encoder_stages.1.2.conv.0.weight
 (160, 320, 3, 3)" fillcolor=lightblue]
	126407094729328 -> 126407054610624
	126407054610624 [label=AccumulateGrad]
	126407054610480 -> 126407054610576
	126407094729408 [label="encoder_stages.1.2.conv.0.bias
 (160)" fillcolor=lightblue]
	126407094729408 -> 126407054610480
	126407054610480 [label=AccumulateGrad]
	126407054610336 -> 126407054610288
	126407094729568 [label="encoder_stages.1.2.conv.2.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094729568 -> 126407054610336
	126407054610336 [label=AccumulateGrad]
	126407054610192 -> 126407054610288
	126407094729648 [label="encoder_stages.1.2.conv.2.bias
 (320)" fillcolor=lightblue]
	126407094729648 -> 126407054610192
	126407054610192 [label=AccumulateGrad]
	126407054610096 -> 126407054609952
	126407054610096 [label=ConvolutionBackward0]
	126407054610672 -> 126407054610096
	126407054610720 -> 126407054610096
	126407094729808 [label="encoder_stages.1.2.residual_conv.weight
 (320, 320, 1, 1)" fillcolor=lightblue]
	126407094729808 -> 126407054610720
	126407054610720 [label=AccumulateGrad]
	126407054610432 -> 126407054610096
	126407094729888 [label="encoder_stages.1.2.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094729888 -> 126407054610432
	126407054610432 [label=AccumulateGrad]
	126407054609904 -> 126407054609856
	126407094730048 [label="encoder_stages.2.0.conv.0.weight
 (192, 320, 3, 3)" fillcolor=lightblue]
	126407094730048 -> 126407054609904
	126407054609904 [label=AccumulateGrad]
	126407054609760 -> 126407054609856
	126407094730128 [label="encoder_stages.2.0.conv.0.bias
 (192)" fillcolor=lightblue]
	126407094730128 -> 126407054609760
	126407054609760 [label=AccumulateGrad]
	126407054609616 -> 126407054609568
	126407094730288 [label="encoder_stages.2.0.conv.2.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094730288 -> 126407054609616
	126407054609616 [label=AccumulateGrad]
	126407054609472 -> 126407054609568
	126407094730368 [label="encoder_stages.2.0.conv.2.bias
 (384)" fillcolor=lightblue]
	126407094730368 -> 126407054609472
	126407054609472 [label=AccumulateGrad]
	126407054609376 -> 126407054609232
	126407054609376 [label=ConvolutionBackward0]
	126407054609952 -> 126407054609376
	126407054610000 -> 126407054609376
	126407094730528 [label="encoder_stages.2.0.residual_conv.weight
 (384, 320, 1, 1)" fillcolor=lightblue]
	126407094730528 -> 126407054610000
	126407054610000 [label=AccumulateGrad]
	126407054609712 -> 126407054609376
	126407094730608 [label="encoder_stages.2.0.residual_conv.bias
 (384)" fillcolor=lightblue]
	126407094730608 -> 126407054609712
	126407054609712 [label=AccumulateGrad]
	126407054609184 -> 126407054609136
	126407094911056 [label="encoder_stages.2.1.conv.0.weight
 (192, 384, 3, 3)" fillcolor=lightblue]
	126407094911056 -> 126407054609184
	126407054609184 [label=AccumulateGrad]
	126407054609040 -> 126407054609136
	126407094911136 [label="encoder_stages.2.1.conv.0.bias
 (192)" fillcolor=lightblue]
	126407094911136 -> 126407054609040
	126407054609040 [label=AccumulateGrad]
	126407054608896 -> 126407054608848
	126407094911296 [label="encoder_stages.2.1.conv.2.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094911296 -> 126407054608896
	126407054608896 [label=AccumulateGrad]
	126407054608752 -> 126407054608848
	126407094911376 [label="encoder_stages.2.1.conv.2.bias
 (384)" fillcolor=lightblue]
	126407094911376 -> 126407054608752
	126407054608752 [label=AccumulateGrad]
	126407054608656 -> 126407054608512
	126407054608656 [label=ConvolutionBackward0]
	126407054609232 -> 126407054608656
	126407054609280 -> 126407054608656
	126407094911536 [label="encoder_stages.2.1.residual_conv.weight
 (384, 384, 1, 1)" fillcolor=lightblue]
	126407094911536 -> 126407054609280
	126407054609280 [label=AccumulateGrad]
	126407054608992 -> 126407054608656
	126407094911616 [label="encoder_stages.2.1.residual_conv.bias
 (384)" fillcolor=lightblue]
	126407094911616 -> 126407054608992
	126407054608992 [label=AccumulateGrad]
	126407054608464 -> 126407054608416
	126407094911696 [label="decoder_stages.0.0.conv1.0.weight
 (192, 384, 3, 3)" fillcolor=lightblue]
	126407094911696 -> 126407054608464
	126407054608464 [label=AccumulateGrad]
	126407054608320 -> 126407054608416
	126407094911776 [label="decoder_stages.0.0.conv1.0.bias
 (192)" fillcolor=lightblue]
	126407094911776 -> 126407054608320
	126407054608320 [label=AccumulateGrad]
	126407054608224 -> 126407054608080
	126407054608224 [label=ConvolutionBackward0]
	126407054609232 -> 126407054608224
	126407054608800 -> 126407054608224
	126407094912176 [label="decoder_stages.0.0.skip_conv.weight
 (192, 384, 1, 1)" fillcolor=lightblue]
	126407094912176 -> 126407054608800
	126407054608800 [label=AccumulateGrad]
	126407054608560 -> 126407054608224
	126407094912256 [label="decoder_stages.0.0.skip_conv.bias
 (192)" fillcolor=lightblue]
	126407094912256 -> 126407054608560
	126407054608560 [label=AccumulateGrad]
	126407054608032 -> 126407054607984
	126407094912416 [label="decoder_stages.0.0.conv2.0.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094912416 -> 126407054608032
	126407054608032 [label=AccumulateGrad]
	126407054607888 -> 126407054607984
	126407094912496 [label="decoder_stages.0.0.conv2.0.bias
 (384)" fillcolor=lightblue]
	126407094912496 -> 126407054607888
	126407054607888 [label=AccumulateGrad]
	126407054607792 -> 126407054607648
	126407054607792 [label=ConvolutionBackward0]
	126407054608512 -> 126407054607792
	126407054608368 -> 126407054607792
	126407094911936 [label="decoder_stages.0.0.residual_conv.weight
 (384, 384, 1, 1)" fillcolor=lightblue]
	126407094911936 -> 126407054608368
	126407054608368 [label=AccumulateGrad]
	126407054608128 -> 126407054607792
	126407094912016 [label="decoder_stages.0.0.residual_conv.bias
 (384)" fillcolor=lightblue]
	126407094912016 -> 126407054608128
	126407054608128 [label=AccumulateGrad]
	126407054607600 -> 126407054607552
	126407094912656 [label="decoder_stages.0.1.conv1.0.weight
 (192, 384, 3, 3)" fillcolor=lightblue]
	126407094912656 -> 126407054607600
	126407054607600 [label=AccumulateGrad]
	126407054607456 -> 126407054607552
	126407094912736 [label="decoder_stages.0.1.conv1.0.bias
 (192)" fillcolor=lightblue]
	126407094912736 -> 126407054607456
	126407054607456 [label=AccumulateGrad]
	126407054607360 -> 126407054607216
	126407054607360 [label=ConvolutionBackward0]
	126407054609952 -> 126407054607360
	126407054607936 -> 126407054607360
	126407094913136 [label="decoder_stages.0.1.skip_conv.weight
 (192, 320, 1, 1)" fillcolor=lightblue]
	126407094913136 -> 126407054607936
	126407054607936 [label=AccumulateGrad]
	126407054607696 -> 126407054607360
	126407094913216 [label="decoder_stages.0.1.skip_conv.bias
 (192)" fillcolor=lightblue]
	126407094913216 -> 126407054607696
	126407054607696 [label=AccumulateGrad]
	126407054607168 -> 126407054607120
	126407094913376 [label="decoder_stages.0.1.conv2.0.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094913376 -> 126407054607168
	126407054607168 [label=AccumulateGrad]
	126407054607024 -> 126407054607120
	126407094913456 [label="decoder_stages.0.1.conv2.0.bias
 (384)" fillcolor=lightblue]
	126407094913456 -> 126407054607024
	126407054607024 [label=AccumulateGrad]
	126407054606928 -> 126407054606784
	126407054606928 [label=ConvolutionBackward0]
	126407054607648 -> 126407054606928
	126407054607504 -> 126407054606928
	126407094912896 [label="decoder_stages.0.1.residual_conv.weight
 (384, 384, 1, 1)" fillcolor=lightblue]
	126407094912896 -> 126407054607504
	126407054607504 [label=AccumulateGrad]
	126407054607264 -> 126407054606928
	126407094912976 [label="decoder_stages.0.1.residual_conv.bias
 (384)" fillcolor=lightblue]
	126407094912976 -> 126407054607264
	126407054607264 [label=AccumulateGrad]
	126407054606736 -> 126407054606688
	126407094913616 [label="decoder_stages.0.2.conv1.0.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094913616 -> 126407054606736
	126407054606736 [label=AccumulateGrad]
	126407054606592 -> 126407054606688
	126407094913696 [label="decoder_stages.0.2.conv1.0.bias
 (192)" fillcolor=lightblue]
	126407094913696 -> 126407054606592
	126407054606592 [label=AccumulateGrad]
	126407054606496 -> 126407094697936
	126407054606496 [label=ConvolutionBackward0]
	126407054610672 -> 126407054606496
	126407054607072 -> 126407054606496
	126407094914096 [label="decoder_stages.0.2.skip_conv.weight
 (192, 320, 1, 1)" fillcolor=lightblue]
	126407094914096 -> 126407054607072
	126407054607072 [label=AccumulateGrad]
	126407054606832 -> 126407054606496
	126407094914176 [label="decoder_stages.0.2.skip_conv.bias
 (192)" fillcolor=lightblue]
	126407094914176 -> 126407054606832
	126407054606832 [label=AccumulateGrad]
	126407094697888 -> 126407094697840
	126407094914336 [label="decoder_stages.0.2.conv2.0.weight
 (384, 192, 3, 3)" fillcolor=lightblue]
	126407094914336 -> 126407094697888
	126407094697888 [label=AccumulateGrad]
	126407094697744 -> 126407094697840
	126407094914416 [label="decoder_stages.0.2.conv2.0.bias
 (384)" fillcolor=lightblue]
	126407094914416 -> 126407094697744
	126407094697744 [label=AccumulateGrad]
	126407094697648 -> 126407094697504
	126407094697648 [label=ConvolutionBackward0]
	126407054606784 -> 126407094697648
	126407094697792 -> 126407094697648
	126407094913856 [label="decoder_stages.0.2.residual_conv.weight
 (384, 384, 1, 1)" fillcolor=lightblue]
	126407094913856 -> 126407094697792
	126407094697792 [label=AccumulateGrad]
	126407054606640 -> 126407094697648
	126407094913936 [label="decoder_stages.0.2.residual_conv.bias
 (384)" fillcolor=lightblue]
	126407094913936 -> 126407054606640
	126407054606640 [label=AccumulateGrad]
	126407094697456 -> 126407094697408
	126407094914576 [label="decoder_stages.1.0.conv1.0.weight
 (160, 384, 3, 3)" fillcolor=lightblue]
	126407094914576 -> 126407094697456
	126407094697456 [label=AccumulateGrad]
	126407094697312 -> 126407094697408
	126407094914656 [label="decoder_stages.1.0.conv1.0.bias
 (160)" fillcolor=lightblue]
	126407094914656 -> 126407094697312
	126407094697312 [label=AccumulateGrad]
	126407094697216 -> 126407094697072
	126407094697216 [label=ConvolutionBackward0]
	126407054611344 -> 126407094697216
	126407094697600 -> 126407094697216
	126407094915056 [label="decoder_stages.1.0.skip_conv.weight
 (160, 320, 1, 1)" fillcolor=lightblue]
	126407094915056 -> 126407094697600
	126407094697600 [label=AccumulateGrad]
	126407094697552 -> 126407094697216
	126407094915136 [label="decoder_stages.1.0.skip_conv.bias
 (160)" fillcolor=lightblue]
	126407094915136 -> 126407094697552
	126407094697552 [label=AccumulateGrad]
	126407094697024 -> 126407094696976
	126407094915296 [label="decoder_stages.1.0.conv2.0.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094915296 -> 126407094697024
	126407094697024 [label=AccumulateGrad]
	126407094696880 -> 126407094696976
	126407094915376 [label="decoder_stages.1.0.conv2.0.bias
 (320)" fillcolor=lightblue]
	126407094915376 -> 126407094696880
	126407094696880 [label=AccumulateGrad]
	126407094696784 -> 126407094696640
	126407094696784 [label=ConvolutionBackward0]
	126407094697504 -> 126407094696784
	126407094697168 -> 126407094696784
	126407094914816 [label="decoder_stages.1.0.residual_conv.weight
 (320, 384, 1, 1)" fillcolor=lightblue]
	126407094914816 -> 126407094697168
	126407094697168 [label=AccumulateGrad]
	126407094697120 -> 126407094696784
	126407094914896 [label="decoder_stages.1.0.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094914896 -> 126407094697120
	126407094697120 [label=AccumulateGrad]
	126407094696592 -> 126407094696544
	126407094915536 [label="decoder_stages.1.1.conv1.0.weight
 (160, 320, 3, 3)" fillcolor=lightblue]
	126407094915536 -> 126407094696592
	126407094696592 [label=AccumulateGrad]
	126407094696448 -> 126407094696544
	126407094915616 [label="decoder_stages.1.1.conv1.0.bias
 (160)" fillcolor=lightblue]
	126407094915616 -> 126407094696448
	126407094696448 [label=AccumulateGrad]
	126407094696352 -> 126407094696208
	126407094696352 [label=ConvolutionBackward0]
	126407054612160 -> 126407094696352
	126407094696928 -> 126407094696352
	126407094916016 [label="decoder_stages.1.1.skip_conv.weight
 (160, 256, 1, 1)" fillcolor=lightblue]
	126407094916016 -> 126407094696928
	126407094696928 [label=AccumulateGrad]
	126407094696688 -> 126407094696352
	126407094916096 [label="decoder_stages.1.1.skip_conv.bias
 (160)" fillcolor=lightblue]
	126407094916096 -> 126407094696688
	126407094696688 [label=AccumulateGrad]
	126407094696160 -> 126407094696112
	126407094916256 [label="decoder_stages.1.1.conv2.0.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094916256 -> 126407094696160
	126407094696160 [label=AccumulateGrad]
	126407094696016 -> 126407094696112
	126407094916336 [label="decoder_stages.1.1.conv2.0.bias
 (320)" fillcolor=lightblue]
	126407094916336 -> 126407094696016
	126407094696016 [label=AccumulateGrad]
	126407094695920 -> 126407094695776
	126407094695920 [label=ConvolutionBackward0]
	126407094696640 -> 126407094695920
	126407094696496 -> 126407094695920
	126407094915776 [label="decoder_stages.1.1.residual_conv.weight
 (320, 320, 1, 1)" fillcolor=lightblue]
	126407094915776 -> 126407094696496
	126407094696496 [label=AccumulateGrad]
	126407094696256 -> 126407094695920
	126407094915856 [label="decoder_stages.1.1.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094915856 -> 126407094696256
	126407094696256 [label=AccumulateGrad]
	126407094695728 -> 126407094695680
	126407094916496 [label="decoder_stages.1.2.conv1.0.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094916496 -> 126407094695728
	126407094695728 [label=AccumulateGrad]
	126407094695584 -> 126407094695680
	126407094916576 [label="decoder_stages.1.2.conv1.0.bias
 (160)" fillcolor=lightblue]
	126407094916576 -> 126407094695584
	126407094695584 [label=AccumulateGrad]
	126407094695488 -> 126407094695344
	126407094695488 [label=ConvolutionBackward0]
	126407054612976 -> 126407094695488
	126407094696064 -> 126407094695488
	126407094916976 [label="decoder_stages.1.2.skip_conv.weight
 (160, 256, 1, 1)" fillcolor=lightblue]
	126407094916976 -> 126407094696064
	126407094696064 [label=AccumulateGrad]
	126407094695824 -> 126407094695488
	126407094917056 [label="decoder_stages.1.2.skip_conv.bias
 (160)" fillcolor=lightblue]
	126407094917056 -> 126407094695824
	126407094695824 [label=AccumulateGrad]
	126407094695296 -> 126407094695248
	126407094917216 [label="decoder_stages.1.2.conv2.0.weight
 (320, 160, 3, 3)" fillcolor=lightblue]
	126407094917216 -> 126407094695296
	126407094695296 [label=AccumulateGrad]
	126407094695152 -> 126407094695248
	126407094917296 [label="decoder_stages.1.2.conv2.0.bias
 (320)" fillcolor=lightblue]
	126407094917296 -> 126407094695152
	126407094695152 [label=AccumulateGrad]
	126407094695056 -> 126407094694912
	126407094695056 [label=ConvolutionBackward0]
	126407094695776 -> 126407094695056
	126407094695632 -> 126407094695056
	126407094916736 [label="decoder_stages.1.2.residual_conv.weight
 (320, 320, 1, 1)" fillcolor=lightblue]
	126407094916736 -> 126407094695632
	126407094695632 [label=AccumulateGrad]
	126407094695392 -> 126407094695056
	126407094916816 [label="decoder_stages.1.2.residual_conv.bias
 (320)" fillcolor=lightblue]
	126407094916816 -> 126407094695392
	126407094695392 [label=AccumulateGrad]
	126407094694864 -> 126407094693712
	126407094917456 [label="decoder_stages.2.0.conv1.0.weight
 (128, 320, 3, 3)" fillcolor=lightblue]
	126407094917456 -> 126407094694864
	126407094694864 [label=AccumulateGrad]
	126407094693088 -> 126407094693712
	126407094917536 [label="decoder_stages.2.0.conv1.0.bias
 (128)" fillcolor=lightblue]
	126407094917536 -> 126407094693088
	126407094693088 [label=AccumulateGrad]
	126407094693472 -> 126407094693568
	126407094693472 [label=ConvolutionBackward0]
	126407054613792 -> 126407094693472
	126407094695200 -> 126407094693472
	126407094917936 [label="decoder_stages.2.0.skip_conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	126407094917936 -> 126407094695200
	126407094695200 [label=AccumulateGrad]
	126407094694960 -> 126407094693472
	126407094918016 [label="decoder_stages.2.0.skip_conv.bias
 (128)" fillcolor=lightblue]
	126407094918016 -> 126407094694960
	126407094694960 [label=AccumulateGrad]
	126407094693520 -> 126407094693232
	126407094918176 [label="decoder_stages.2.0.conv2.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	126407094918176 -> 126407094693520
	126407094693520 [label=AccumulateGrad]
	126407094693184 -> 126407094693232
	126407094918256 [label="decoder_stages.2.0.conv2.0.bias
 (256)" fillcolor=lightblue]
	126407094918256 -> 126407094693184
	126407094693184 [label=AccumulateGrad]
	126407094694240 -> 126407094693952
	126407094694240 [label=ConvolutionBackward0]
	126407094694912 -> 126407094694240
	126407094693136 -> 126407094694240
	126407094917696 [label="decoder_stages.2.0.residual_conv.weight
 (256, 320, 1, 1)" fillcolor=lightblue]
	126407094917696 -> 126407094693136
	126407094693136 [label=AccumulateGrad]
	126407094694096 -> 126407094694240
	126407094917776 [label="decoder_stages.2.0.residual_conv.bias
 (256)" fillcolor=lightblue]
	126407094917776 -> 126407094694096
	126407094694096 [label=AccumulateGrad]
	126407094693904 -> 126407094694192
	126407094918416 [label="decoder_stages.2.1.conv1.0.weight
 (128, 256, 3, 3)" fillcolor=lightblue]
	126407094918416 -> 126407094693904
	126407094693904 [label=AccumulateGrad]
	126407094693424 -> 126407094694192
	126407094918496 [label="decoder_stages.2.1.conv1.0.bias
 (128)" fillcolor=lightblue]
	126407094918496 -> 126407094693424
	126407094693424 [label=AccumulateGrad]
	126407094693328 -> 126407094693664
	126407094693328 [label=ConvolutionBackward0]
	126407054614608 -> 126407094693328
	126407094687424 -> 126407094693328
	126407094918896 [label="decoder_stages.2.1.skip_conv.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	126407094918896 -> 126407094687424
	126407094687424 [label=AccumulateGrad]
	126407094694000 -> 126407094693328
	126407094918976 [label="decoder_stages.2.1.skip_conv.bias
 (128)" fillcolor=lightblue]
	126407094918976 -> 126407094694000
	126407094694000 [label=AccumulateGrad]
	126407094694816 -> 126407094692944
	126407094919136 [label="decoder_stages.2.1.conv2.0.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	126407094919136 -> 126407094694816
	126407094694816 [label=AccumulateGrad]
	126407094694672 -> 126407094692944
	126407094919216 [label="decoder_stages.2.1.conv2.0.bias
 (256)" fillcolor=lightblue]
	126407094919216 -> 126407094694672
	126407094694672 [label=AccumulateGrad]
	126407094693856 -> 126407098360176
	126407094693856 [label=ConvolutionBackward0]
	126407094693952 -> 126407094693856
	126407094694144 -> 126407094693856
	126407094918656 [label="decoder_stages.2.1.residual_conv.weight
 (256, 256, 1, 1)" fillcolor=lightblue]
	126407094918656 -> 126407094694144
	126407094694144 [label=AccumulateGrad]
	126407094692992 -> 126407094693856
	126407094918736 [label="decoder_stages.2.1.residual_conv.bias
 (256)" fillcolor=lightblue]
	126407094918736 -> 126407094692992
	126407094692992 [label=AccumulateGrad]
	126407098360176 -> 126407094920736
}
